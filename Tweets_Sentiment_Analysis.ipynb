{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveenk-DS/twitter_sentiment_app.py/blob/main.py/Tweets_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46f30fee-fffd-46a5-8490-a6d740112af4",
      "metadata": {
        "id": "46f30fee-fffd-46a5-8490-a6d740112af4",
        "outputId": "4a2e832e-c3c9-4d0a-9da5-27f0ec827164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cull7\n",
            "Requirement already satisfied: torch in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (0.20.0)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.1.4)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement fsspec (from torch) (from versions: none)\n",
            "ERROR: No matching distribution found for fsspec\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cull7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c70086d1-b17b-4d56-b963-aba19aca1d22",
      "metadata": {
        "id": "c70086d1-b17b-4d56-b963-aba19aca1d22",
        "outputId": "05cfe713-c95b-4c6f-ca68-063080ae2629"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2401</th>\n",
              "      <th>Borderlands</th>\n",
              "      <th>Positive</th>\n",
              "      <th>im getting on borderlands and i will murder you all ,</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   2401  Borderlands  Positive  \\\n",
              "0  2401  Borderlands  Positive   \n",
              "1  2401  Borderlands  Positive   \n",
              "2  2401  Borderlands  Positive   \n",
              "3  2401  Borderlands  Positive   \n",
              "4  2401  Borderlands  Positive   \n",
              "\n",
              "  im getting on borderlands and i will murder you all ,  \n",
              "0  I am coming to the borders and I will kill you...     \n",
              "1  im getting on borderlands and i will kill you ...     \n",
              "2  im coming on borderlands and i will murder you...     \n",
              "3  im getting on borderlands 2 and i will murder ...     \n",
              "4  im getting into borderlands and i can murder y...     "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url= \"https://raw.githubusercontent.com/GuviMentor88/Training-Datasets/refs/heads/main/twitter_training.csv\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "df=pd.read_csv(url)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69735653-850a-45c0-9b36-a3506babd8be",
      "metadata": {
        "id": "69735653-850a-45c0-9b36-a3506babd8be",
        "outputId": "d6754156-fdbb-4a1f-a430-642c58c9ffcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Tweet_id     Location    Review  \\\n",
            "0          2401  Borderlands  Positive   \n",
            "1          2401  Borderlands  Positive   \n",
            "2          2401  Borderlands  Positive   \n",
            "3          2401  Borderlands  Positive   \n",
            "4          2401  Borderlands  Positive   \n",
            "...         ...          ...       ...   \n",
            "74676      9200       Nvidia  Positive   \n",
            "74677      9200       Nvidia  Positive   \n",
            "74678      9200       Nvidia  Positive   \n",
            "74679      9200       Nvidia  Positive   \n",
            "74680      9200       Nvidia  Positive   \n",
            "\n",
            "                                                  Tweets  \n",
            "0      I am coming to the borders and I will kill you...  \n",
            "1      im getting on borderlands and i will kill you ...  \n",
            "2      im coming on borderlands and i will murder you...  \n",
            "3      im getting on borderlands 2 and i will murder ...  \n",
            "4      im getting into borderlands and i can murder y...  \n",
            "...                                                  ...  \n",
            "74676  Just realized that the Windows partition of my...  \n",
            "74677  Just realized that my Mac window partition is ...  \n",
            "74678  Just realized the windows partition of my Mac ...  \n",
            "74679  Just realized between the windows partition of...  \n",
            "74680  Just like the windows partition of my Mac is l...  \n",
            "\n",
            "[74681 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Assigning column names\n",
        "df.columns = ['Tweet_id', 'Location', 'Review', 'Tweets']\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2326285-5445-46be-a498-9124b2a244ae",
      "metadata": {
        "id": "f2326285-5445-46be-a498-9124b2a244ae",
        "outputId": "d7ac949b-8a33-4e89-fe54-06b5601ec4f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(74681, 4)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a8b1c2-f7b7-4fe8-8239-f53bf85fd415",
      "metadata": {
        "id": "b5a8b1c2-f7b7-4fe8-8239-f53bf85fd415",
        "outputId": "054f1172-4921-48ff-f315-9f1510f63dde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74681 entries, 0 to 74680\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Tweet_id  74681 non-null  int64 \n",
            " 1   Location  74681 non-null  object\n",
            " 2   Review    74681 non-null  object\n",
            " 3   Tweets    73995 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b45b43-d83a-4104-bc49-58ed6d2c6551",
      "metadata": {
        "id": "61b45b43-d83a-4104-bc49-58ed6d2c6551",
        "outputId": "e6f8c353-d388-46fb-a64b-494d8c5f001c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tweet_id      0\n",
              "Location      0\n",
              "Review        0\n",
              "Tweets      686\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e54211-2384-45de-afee-bf4b0b7ab6b5",
      "metadata": {
        "id": "94e54211-2384-45de-afee-bf4b0b7ab6b5",
        "outputId": "2d2482e0-bc7b-4c84-8cca-f60d82f16e96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2700"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#duplicate\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d940c28-99ca-4827-8b25-4ae03177daa9",
      "metadata": {
        "id": "1d940c28-99ca-4827-8b25-4ae03177daa9"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37df42e-5b19-42b6-a290-e395e8fe181c",
      "metadata": {
        "id": "d37df42e-5b19-42b6-a290-e395e8fe181c"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['Tweet_id', 'Location'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8983052b-e53c-4ad6-a320-453787ff108e",
      "metadata": {
        "id": "8983052b-e53c-4ad6-a320-453787ff108e"
      },
      "outputs": [],
      "source": [
        "# Replace \"Irrelevant\" with \"Neutral\"\n",
        "df['Review'] = df['Review'].replace('Irrelevant', 'Neutral')\n",
        "\n",
        "# Label Encoding\n",
        "sentiment_mapping = {'Positive': 1, 'Negative': 2, 'Neutral': 0}\n",
        "df['Review'] = df['Review'].map(sentiment_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2fdaf8-4cb7-4b7f-9144-1ac9d59a3067",
      "metadata": {
        "id": "be2fdaf8-4cb7-4b7f-9144-1ac9d59a3067",
        "outputId": "66aa372b-37b1-4989-ba8b-ad9511dadc16"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df.groupby('Review').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e7e29e-444e-4c06-860a-11a6cf2d72cf",
      "metadata": {
        "id": "91e7e29e-444e-4c06-860a-11a6cf2d72cf"
      },
      "outputs": [],
      "source": [
        "df.to_csv(r\"E:\\UDHAYA\\Final_Project\\Cleaned_Dataset\\Cleaned_Tweets_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d67b75-68ab-4c10-be1d-91eacc757567",
      "metadata": {
        "id": "47d67b75-68ab-4c10-be1d-91eacc757567",
        "outputId": "8a70e26d-8b0f-4f35-ab33-2f8d2e795218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (4.46.3)\n",
            "Requirement already satisfied: datasets in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (1.3.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (3.10.11)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets torch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8cdee28-d4b7-4173-a787-0230a3f980f7",
      "metadata": {
        "id": "e8cdee28-d4b7-4173-a787-0230a3f980f7",
        "outputId": "48f39a76-544d-4dab-aaee-3bd017eb436a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16876990-38dd-4c3e-84dd-f490d79f63a6",
      "metadata": {
        "id": "16876990-38dd-4c3e-84dd-f490d79f63a6"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d372f78-6ce2-46c4-8ee9-95276a960916",
      "metadata": {
        "id": "3d372f78-6ce2-46c4-8ee9-95276a960916"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load your preprocessed dataset\n",
        "df = pd.read_csv(r\"E:\\UDHAYA\\Final_Project\\Cleaned_Dataset\\Cleaned_Tweets_dataset.csv\")  # Replace with actual file path\n",
        "\n",
        "# Train-test split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['Tweets'], df['Review'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert the 'text' column to strings before creating the Dataset\n",
        "train_texts = train_texts.astype(str)\n",
        "val_texts = val_texts.astype(str)\n",
        "# Convert to Dataset objects\n",
        "train_data = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
        "val_data = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41606386-8dfc-4628-af4a-4615f31eb530",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "529e6f3cb082446eaf36c6f55f8e6688",
            "9c5c1bb38d7743b492268abe4c51182b"
          ]
        },
        "id": "41606386-8dfc-4628-af4a-4615f31eb530",
        "outputId": "e850d714-7288-4bc9-fdcf-226565301675"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "529e6f3cb082446eaf36c6f55f8e6688",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/57324 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5c1bb38d7743b492268abe4c51182b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14331 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "train_data = train_data.map(tokenize_function, batched=True)\n",
        "val_data = val_data.map(tokenize_function, batched=True)\n",
        "\n",
        "# Remove unnecessary columns for training\n",
        "train_data = train_data.remove_columns(['text'])\n",
        "val_data = val_data.remove_columns(['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78bc537-a95b-45f5-a5ee-32330e3dbf0c",
      "metadata": {
        "id": "c78bc537-a95b-45f5-a5ee-32330e3dbf0c",
        "outputId": "c4d6b033-7995-4eaa-9ee2-a42eafac85bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=3  # Number of sentiment classes (Positive, Negative, Neutral)\n",
        ")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664c202f-2ffb-41f5-871f-6eebf980b761",
      "metadata": {
        "id": "664c202f-2ffb-41f5-871f-6eebf980b761"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2c0312-b884-4bb5-8721-0b0b6c2ee79d",
      "metadata": {
        "id": "3f2c0312-b884-4bb5-8721-0b0b6c2ee79d"
      },
      "outputs": [],
      "source": [
        "# Create a PyTorch Dataset\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad36b30-a9e4-4121-9544-2dd4fa0b3ebb",
      "metadata": {
        "id": "2ad36b30-a9e4-4121-9544-2dd4fa0b3ebb",
        "outputId": "8eb71664-3fde-46d8-f1cb-6890224896be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55377d3e-9bbf-49fc-af3d-c21ac01720e2",
      "metadata": {
        "id": "55377d3e-9bbf-49fc-af3d-c21ac01720e2",
        "outputId": "51244d84-b8bb-49c9-aa7c-a75847d03ed4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\akila\\AppData\\Local\\Temp\\ipykernel_26112\\2969086742.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "C:\\Users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:403: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10749' max='10749' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10749/10749 1:07:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.396200</td>\n",
              "      <td>0.447499</td>\n",
              "      <td>0.827856</td>\n",
              "      <td>0.828197</td>\n",
              "      <td>0.827856</td>\n",
              "      <td>0.827309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.207800</td>\n",
              "      <td>0.302091</td>\n",
              "      <td>0.891634</td>\n",
              "      <td>0.892261</td>\n",
              "      <td>0.891634</td>\n",
              "      <td>0.891660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.227500</td>\n",
              "      <td>0.325460</td>\n",
              "      <td>0.906985</td>\n",
              "      <td>0.907476</td>\n",
              "      <td>0.906985</td>\n",
              "      <td>0.906902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10749, training_loss=0.3712027873568384, metrics={'train_runtime': 4038.179, 'train_samples_per_second': 42.587, 'train_steps_per_second': 2.662, 'total_flos': 2.278108974281933e+16, 'train_loss': 0.3712027873568384, 'epoch': 3.0})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stop if no improvement after 2 epochs\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18329d4-1a1f-4579-81f2-1e7cb2d130e7",
      "metadata": {
        "id": "d18329d4-1a1f-4579-81f2-1e7cb2d130e7",
        "outputId": "cecf1d70-1b09-47c6-f739-b67fea6ab718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Results: {'eval_loss': 0.30209147930145264, 'eval_accuracy': 0.8916335217360966, 'eval_precision': 0.8922611806722309, 'eval_recall': 0.8916335217360966, 'eval_f1': 0.8916598375248648, 'eval_runtime': 135.661, 'eval_samples_per_second': 105.638, 'eval_steps_per_second': 6.605, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a56f5a2c-debd-4109-80b9-d6547fccab6e",
      "metadata": {
        "id": "a56f5a2c-debd-4109-80b9-d6547fccab6e",
        "outputId": "148a1971-088d-47e0-aaff-4e90f3c02c7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\\\\tokenizer_config.json',\n",
              " 'E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\\\\special_tokens_map.json',\n",
              " 'E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\\\\vocab.txt',\n",
              " 'E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\\\\added_tokens.json')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\")\n",
        "tokenizer.save_pretrained(\"E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c25281-9ee4-4f65-8382-22200187dcf8",
      "metadata": {
        "id": "37c25281-9ee4-4f65-8382-22200187dcf8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load fine-tuned model and tokenizer\n",
        "model_path = \"E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afbd12a9-c7ad-4ad7-968f-bc54c7c619ba",
      "metadata": {
        "id": "afbd12a9-c7ad-4ad7-968f-bc54c7c619ba"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(texts):\n",
        "    # Tokenize input texts\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = F.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Get class probabilities and format the output\n",
        "    results = []\n",
        "    for i, prob in enumerate(probs):\n",
        "        result = {\n",
        "            \"Text\": texts[i],\n",
        "            \"Probabilities\": {\n",
        "                \"Neutral\": round(prob[0].item(), 4),\n",
        "                \"Positive\": round(prob[1].item(), 4),\n",
        "                \"Negative\": round(prob[2].item(), 4)\n",
        "            }\n",
        "        }\n",
        "        results.append(result)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f94d2c-6df9-4cb0-a91a-ddb3728430a9",
      "metadata": {
        "id": "a5f94d2c-6df9-4cb0-a91a-ddb3728430a9",
        "outputId": "4b1a7193-2707-44b1-ac2e-b614ac759e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: I love this product!\n",
            "  Neutral: 0.0166\n",
            "  Positive: 0.9785\n",
            "  Negative: 0.0049\n",
            "\n",
            "Text: This is the worst experience ever.\n",
            "  Neutral: 0.0174\n",
            "  Positive: 0.0135\n",
            "  Negative: 0.9691\n",
            "\n",
            "Text: guvi has the best data science road map in industry\n",
            "  Neutral: 0.9273\n",
            "  Positive: 0.0682\n",
            "  Negative: 0.0045\n",
            "\n"
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    \"I love this product!\",\n",
        "    \"This is the worst experience ever.\",\n",
        "    \"guvi has the best data science road map in industry\"\n",
        "]\n",
        "\n",
        "predictions = predict_sentiment(texts)\n",
        "\n",
        "# Display results\n",
        "for prediction in predictions:\n",
        "    print(f\"Text: {prediction['Text']}\")\n",
        "    for sentiment, prob in prediction[\"Probabilities\"].items():\n",
        "        print(f\"  {sentiment}: {prob}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee582a6e-9bf4-4a52-aac6-4d712af4b6ab",
      "metadata": {
        "id": "ee582a6e-9bf4-4a52-aac6-4d712af4b6ab",
        "outputId": "b728f701-58f2-477b-be73-823c76c1ab48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug>=3.0.0 (from flask)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from flask) (3.1.4)\n",
            "Collecting itsdangerous>=2.1.2 (from flask)\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: click>=8.1.3 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from flask) (8.1.8)\n",
            "Collecting blinker>=1.6.2 (from flask)\n",
            "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from flask) (7.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from importlib-metadata>=3.6.0->flask) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\akila\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
            "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "Installing collected packages: Werkzeug, itsdangerous, blinker, flask\n",
            "Successfully installed Werkzeug-3.0.6 blinker-1.8.2 flask-3.0.3 itsdangerous-2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab8843d-6daf-4603-8adc-053033122af5",
      "metadata": {
        "id": "eab8843d-6daf-4603-8adc-053033122af5",
        "outputId": "faeb3a58-0182-4647-bf9b-1970d3351330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7862\n",
            "\n",
            "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IP: Unknown IP | Input: good morning!!! I am very HAPPY today\n",
            "IP: Unknown IP | Input: This is  a Great day!!! Good night all...\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from flask import request\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Load fine-tuned model and tokenizer\n",
        "model_path = \"E:/UDHAYA/Final_Project/Model./fine_tuned_distilbert\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    filename=\"user_logs.txt\",  # Logs will be saved to this file\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(message)s\",\n",
        ")\n",
        "\n",
        "def log_user_details(user_ip, input_text):\n",
        "    log_message = f\"IP: {user_ip} | Input: {input_text}\"\n",
        "    logging.info(log_message)\n",
        "    print(log_message)  # Optional: Print logs for testing in Colab\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    # Get user IP address (only works with Flask requests)\n",
        "    user_ip = request.remote_addr if request else \"Unknown IP\"\n",
        "    log_user_details(user_ip, text)\n",
        "\n",
        "    # Predict sentiment\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    probs = F.softmax(outputs.logits, dim=-1)\n",
        "    # Get class probabilities and format the output\n",
        "    result = {\n",
        "        \"Negative\": round(probs[0][2].item(), 4),\n",
        "        \"Neutral\": round(probs[0][0].item(), 4),\n",
        "        \"Positive\": round(probs[0][1].item(), 4),\n",
        "    }\n",
        "    return result\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_sentiment,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter text here...\"),\n",
        "    outputs=gr.JSON(),\n",
        "    title=\"Twitter Tweets Sentiment Analysis\",\n",
        "    description=\"Enter Tweets and get the predicted sentiment probabilities.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)  # `share=True` creates a public URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb4e85e-9a56-40a6-b2d7-b8203df494c7",
      "metadata": {
        "id": "0bb4e85e-9a56-40a6-b2d7-b8203df494c7",
        "outputId": "6c7319e8-f418-47c5-aa90-ff967aff8648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Logs:\n",
            "2025-01-10 20:58:58,159 - HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 20:58:58,183 - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 20:58:58,581 - HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
            "2025-01-10 20:58:59,146 - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 20:58:59,468 - HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 20:59:00,123 - HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_windows_amd64.exe \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 21:00:30,042 - IP: Unknown IP | Input: I am peaceful!!! but not happy!\n",
            "2025-01-10 21:01:29,785 - IP: Unknown IP | Input:\n",
            "2025-01-10 21:01:37,213 - IP: Unknown IP | Input: happy!!\n",
            "2025-01-10 23:28:27,645 - HTTP Request: GET http://127.0.0.1:7861/startup-events \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 23:28:27,683 - HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 23:28:28,542 - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 23:28:29,028 - HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "2025-01-10 23:29:17,586 - IP: Unknown IP | Input: I am happy to announce that i have completed my Data science course at guvi!\n",
            "2025-01-10 23:30:09,621 - IP: Unknown IP | Input: I am happy!!!\n",
            "2025-01-12 00:19:11,765 - HTTP Request: GET http://127.0.0.1:7862/startup-events \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 00:19:11,781 - HTTP Request: HEAD http://127.0.0.1:7862/ \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 00:19:12,928 - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 00:19:13,060 - HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 00:19:34,836 - IP: Unknown IP | Input: good morning!!! I am very HAPPY today\n",
            "2025-01-12 00:36:03,608 - IP: Unknown IP | Input: This is  a Great day!!! Good night all...\n"
          ]
        }
      ],
      "source": [
        "# Read the log file and print its content\n",
        "log_file_path = \"user_logs.txt\"\n",
        "\n",
        "try:\n",
        "    with open(log_file_path, \"r\") as log_file:\n",
        "        logs = log_file.readlines()\n",
        "        print(\"User Logs:\")\n",
        "        for line in logs:\n",
        "            print(line.strip())  # Remove extra newline characters\n",
        "except FileNotFoundError:\n",
        "    print(f\"Log file '{log_file_path}' not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3f042f-7514-4e00-a0a1-cf1c96d526ea",
      "metadata": {
        "id": "3b3f042f-7514-4e00-a0a1-cf1c96d526ea"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}